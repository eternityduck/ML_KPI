{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Rn7ihJpZw0E"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-1-public/blob/main/C4/W2/ungraded_labs/C4_W2_Lab_3_deep_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5S4XCUZ6GH7"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOjujz601HcS"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd\n",
        "\n",
        "# Replace the file ID with your own\n",
        "file_id = '1MCs9BTb74j8zHFgS5flxegFSh14dm-c2'\n",
        "link = f'https://drive.google.com/uc?id={file_id}'\n",
        "data = pd.read_csv(link, header=None)\n",
        "print(data)\n",
        "\n",
        "X = data.drop(4, axis=1)\n",
        "y = data[4]\n",
        "\n",
        "print(X)\n",
        "print(y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjC8TSkp6IiH"
      },
      "source": [
        "## Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zswl7jRtGzkk"
      },
      "outputs": [],
      "source": [
        "def plotilka_loss_epochs(history):\n",
        "  plt.plot(history['loss'], label='Test')\n",
        "  plt.plot(history['val_loss'], label='Train')\n",
        "\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1CL6Bh86TS1"
      },
      "source": [
        "## Binary crossentropy/Logistic loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MFtI3X1FErU"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.metrics import *\n",
        "\n",
        "\n",
        "model_binary_crossentropy = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1776, activation='relu'),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_binary_crossentropy.compile(optimizer=RMSprop(learning_rate=1e-4),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "binary_crossentropy_history = model_binary_crossentropy.fit(X, y, epochs=15, batch_size=32, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plotilka_loss_epochs(binary_crossentropy_history.history)"
      ],
      "metadata": {
        "id": "mlj7WN8kuPF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2YvxWcI6lnB"
      },
      "source": [
        "## Adaboost loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Db9kkYnOFKYr"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Exp_Loss(tf.keras.losses.Loss):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    @tf.function\n",
        "    def __call__(self, y_true, y_pred, sample_weight):\n",
        "        #losses = tf.cond(tf.math.reduce_all(tf.equal(y_true,1)), lambda: tf.math.exp(-y_pred), lambda: tf.math.exp(y_pred))\n",
        "        losses = tf.math.exp(-y_true * y_pred + (1 - y_true) * y_pred)\n",
        "        return tf.reduce_mean(losses)\n",
        "\n",
        "model_adaboost_loss = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1776, activation='relu'),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_adaboost_loss.compile(optimizer=RMSprop(learning_rate=1e-4),\n",
        "              loss=Exp_Loss(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "adaboost_history = model_adaboost_loss.fit(X, tf.cast(y, dtype=tf.float32), epochs=15, batch_size=32, validation_split=0.2)\n",
        "\n",
        "plotilka_loss_epochs(adaboost_history.history)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(adaboost_history.history['loss'], label='adaboost-train')\n",
        "plt.plot(binary_crossentropy_history.history['loss'], label='binary-train')\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(adaboost_history.history['val_loss'], label='adaboost-val')\n",
        "plt.plot(binary_crossentropy_history.history['val_loss'], label='binary-val')\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8w1roNiZw3JD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conclusion\n",
        "In our experiments, we experimented with classifing NN by applying different two loss functions: Exponential loss function and Cross-entropy loss function(which turns into more simpified form - binary cross-entropy in our case).\n",
        "\n",
        "Cross-entropy loss function is the most common function for single-label clasifying task and we took is as a base for comparison.\n",
        "\n",
        "Exponential loss function is designed to be more sensitive to outliers. In our case there's no outliers for binary single-label classification task, so the function performs worser and trains model slower."
      ],
      "metadata": {
        "id": "duIu_KHU2PgE"
      }
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
